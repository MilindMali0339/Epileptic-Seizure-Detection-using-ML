{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMv3IhQ76pnH8YTr3kIu4KT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MilindMali0339/Epileptic-Seizure-Detection-using-ML/blob/main/FCM%2BComplecity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-fuzzy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxbXg5ePG2Ny",
        "outputId": "cdce60a8-9038-4977-d9cc-9ed34b032836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-fuzzy\n",
            "  Downloading scikit-fuzzy-0.4.2.tar.gz (993 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m994.0/994.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-fuzzy) (1.25.2)\n",
            "Requirement already satisfied: scipy>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from scikit-fuzzy) (1.11.4)\n",
            "Requirement already satisfied: networkx>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from scikit-fuzzy) (3.3)\n",
            "Building wheels for collected packages: scikit-fuzzy\n",
            "  Building wheel for scikit-fuzzy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-fuzzy: filename=scikit_fuzzy-0.4.2-py3-none-any.whl size=894078 sha256=4acc9f5d1a25937131b9893e516906abf10a149cfdf993cb9f83fa1463627ac1\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/86/1b/dfd97134a2c8313e519bcebd95d3fedc7be7944db022094bc8\n",
            "Successfully built scikit-fuzzy\n",
            "Installing collected packages: scikit-fuzzy\n",
            "Successfully installed scikit-fuzzy-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade scikit-fuzzy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeWigYGbG72K",
        "outputId": "a83786e6-732d-45d5-c69a-a7f7335245d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-fuzzy in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-fuzzy) (1.25.2)\n",
            "Requirement already satisfied: scipy>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from scikit-fuzzy) (1.11.4)\n",
            "Requirement already satisfied: networkx>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from scikit-fuzzy) (3.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from scipy.signal import butter, filtfilt\n",
        "from scipy.stats import kurtosis, skew\n",
        "from scipy.signal import welch\n",
        "import skfuzzy as fuzz\n",
        "\n",
        "# Load EEG signal dataset\n",
        "filenam = '/content/s00.csv';\n",
        "def load_data(filenam):\n",
        "    start_time = time.time()\n",
        "    eeg_data = pd.read_csv('/content/s00.csv')  # Load data from CSV file\n",
        "    end_time = time.time()\n",
        "    print(f\"Data loading time: {end_time - start_time} seconds\")\n",
        "    return eeg_data\n",
        "\n",
        "# Define bandpass filter function\n",
        "def bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
        "    nyquist = 0.5 * fs\n",
        "    low = lowcut / nyquist\n",
        "    high = highcut / nyquist\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    return filtfilt(b, a, data)\n",
        "\n",
        "# Apply bandpass filter to each channel and create filtered_signal columns\n",
        "def preprocess_data(data):\n",
        "    start_time = time.time()\n",
        "    filtered_signals = {}\n",
        "    for i, col in enumerate(data.columns[1:], 1):  # Start from index 1 to skip the first column\n",
        "        print(f\"Filtering data for {col}...\")\n",
        "        filtered_signals[f'filtered_signal_{i}'] = bandpass_filter(data[col], lowcut=0.5, highcut=50, fs=1000)\n",
        "    end_time = time.time()\n",
        "    print(f\"Data preprocessing time: {end_time - start_time} seconds\")\n",
        "    return pd.DataFrame(filtered_signals)\n",
        "\n",
        "# Function to extract time domain features from a signal\n",
        "def extract_time_domain_features(signal):\n",
        "    start_time = time.time()\n",
        "    features = {}\n",
        "    features['mean'] = np.mean(signal)\n",
        "    features['std'] = np.std(signal)\n",
        "    features['max'] = np.max(signal)\n",
        "    features['min'] = np.min(signal)\n",
        "    features['median'] = np.median(signal)\n",
        "    features['kurtosis'] = kurtosis(signal)\n",
        "    features['skewness'] = skew(signal)\n",
        "    end_time = time.time()\n",
        "    print(f\"Time domain feature extraction time: {end_time - start_time} seconds\")\n",
        "    return features\n",
        "\n",
        "# Function to extract frequency domain features from a signal\n",
        "def extract_frequency_domain_features(signal, fs):\n",
        "    start_time = time.time()\n",
        "    f, Pxx = welch(signal, fs=fs, nperseg=fs*2, noverlap=fs)\n",
        "    features = {}\n",
        "    features['spectral_centroid'] = np.sum(f * Pxx) / np.sum(Pxx)\n",
        "    features['spectral_entropy'] = -np.sum(Pxx * np.log2(Pxx))\n",
        "    features['total_power'] = np.sum(Pxx)\n",
        "    end_time = time.time()\n",
        "    print(f\"Frequency domain feature extraction time: {end_time - start_time} seconds\")\n",
        "    return features\n",
        "\n",
        "# Extract features from each filtered channel\n",
        "def extract_features(filtered_signals):\n",
        "    start_time = time.time()\n",
        "    extracted_features = {}\n",
        "    for i, (col, signal) in enumerate(filtered_signals.items(), 1):\n",
        "        print(f\"Extracting features for {col}...\")\n",
        "        time_features = extract_time_domain_features(signal)\n",
        "        frequency_features = extract_frequency_domain_features(signal, fs=1000)\n",
        "        features = {**time_features, **frequency_features}\n",
        "        extracted_features[f'channel_{i}'] = features\n",
        "    end_time = time.time()\n",
        "    print(f\"Feature extraction time: {end_time - start_time} seconds\")\n",
        "    return pd.DataFrame(extracted_features).T\n",
        "\n",
        "# Perform Fuzzy C-Means clustering on the extracted features\n",
        "def perform_clustering(X, num_clusters):\n",
        "    start_time = time.time()\n",
        "    cntr, _, _, _, _, _, _ = fuzz.cluster.cmeans(\n",
        "        X.T, num_clusters, 2, error=0.005, maxiter=1000)\n",
        "    end_time = time.time()\n",
        "    print(f\"Clustering time: {end_time - start_time} seconds\")\n",
        "    return cntr\n",
        "\n",
        "# Assign data points to clusters based on fuzzy clustering centers\n",
        "num_clusters = 2;\n",
        "def assign_to_clusters(X, cntr):\n",
        "    start_time = time.time()\n",
        "    cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(\n",
        "    X.T, num_clusters, 2, error=0.005, maxiter=1000)\n",
        "    end_time = time.time()\n",
        "    print(f\"Assigning to clusters time: {end_time - start_time} seconds\")\n",
        "    return np.argmax(u, axis=0)\n",
        "\n",
        "# Train KNN model\n",
        "def train_knn(X_train, y_train, n_neighbors=5):\n",
        "    start_time = time.time()\n",
        "    knn_model = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn_model.fit(X_train, y_train)\n",
        "    end_time = time.time()\n",
        "    print(f\"KNN training time: {end_time - start_time} seconds\")\n",
        "    return knn_model\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    start_time = time.time()\n",
        "    # Load data\n",
        "    eeg_data = load_data('s00.csv')  # Replace 's00.csv' with your filename\n",
        "\n",
        "    # Preprocess data (filtering)\n",
        "    filtered_signals = preprocess_data(eeg_data)\n",
        "\n",
        "    # Extract features\n",
        "    X = extract_features(filtered_signals)\n",
        "\n",
        "    # Perform clustering\n",
        "    num_clusters = 2  # You can adjust the number of clusters\n",
        "    cntr = perform_clustering(X, num_clusters)\n",
        "\n",
        "    # Assign data points to clusters\n",
        "    y_clusters = assign_to_clusters(X, cntr)\n",
        "\n",
        "    # Train KNN model on cluster assignments\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y_clusters, test_size=0.2, random_state=42)\n",
        "    knn_model = train_knn(X_train, y_train)\n",
        "\n",
        "    # Evaluate model\n",
        "    print(\"Test Set Performance:\")\n",
        "    y_pred = knn_model.predict(X_test)\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    print(\"Confusion Matrix:\\n\", pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True))\n",
        "\n",
        "    # Predict cluster assignments for test set features\n",
        "    y_pred_clusters = knn_model.predict(X_test)\n",
        "\n",
        "    # Define decision rule (example: majority vote)\n",
        "    # Assuming cluster 0 represents non-seizure and cluster 1 represents seizure\n",
        "    seizure_detected = (y_pred_clusters == 1).any()\n",
        "\n",
        "    # Print result\n",
        "    if seizure_detected:\n",
        "        print(\"Seizure detected.\")\n",
        "    else:\n",
        "        print(\"No seizure detected.\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Total execution time(Computation complexity): {end_time - start_time} seconds\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPf3k992G8nX",
        "outputId": "363c16ee-88be-47d4-ff0a-cd6fb026ece3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loading time: 0.15334558486938477 seconds\n",
            "Filtering data for -2.7403...\n",
            "Filtering data for -2.5017...\n",
            "Filtering data for 0.095121...\n",
            "Filtering data for -7.0917...\n",
            "Filtering data for -0.42704...\n",
            "Filtering data for -2.5918...\n",
            "Filtering data for -3.3238...\n",
            "Filtering data for 0.9995...\n",
            "Filtering data for 0.87011...\n",
            "Filtering data for -0.080058...\n",
            "Filtering data for 2.8075...\n",
            "Filtering data for -0.52398...\n",
            "Filtering data for 1.9341...\n",
            "Filtering data for -3.7614...\n",
            "Filtering data for -1.144...\n",
            "Filtering data for 0.033687...\n",
            "Filtering data for 2.7164...\n",
            "Filtering data for 0.84831...\n",
            "Data preprocessing time: 0.10546684265136719 seconds\n",
            "Extracting features for filtered_signal_1...\n",
            "Time domain feature extraction time: 0.0057964324951171875 seconds\n",
            "Frequency domain feature extraction time: 0.0023353099822998047 seconds\n",
            "Extracting features for filtered_signal_2...\n",
            "Time domain feature extraction time: 0.004986286163330078 seconds\n",
            "Frequency domain feature extraction time: 0.002103090286254883 seconds\n",
            "Extracting features for filtered_signal_3...\n",
            "Time domain feature extraction time: 0.00502467155456543 seconds\n",
            "Frequency domain feature extraction time: 0.0020449161529541016 seconds\n",
            "Extracting features for filtered_signal_4...\n",
            "Time domain feature extraction time: 0.008867502212524414 seconds\n",
            "Frequency domain feature extraction time: 0.002034902572631836 seconds\n",
            "Extracting features for filtered_signal_5...\n",
            "Time domain feature extraction time: 0.004966259002685547 seconds\n",
            "Frequency domain feature extraction time: 0.008325338363647461 seconds\n",
            "Extracting features for filtered_signal_6...\n",
            "Time domain feature extraction time: 0.005098104476928711 seconds\n",
            "Frequency domain feature extraction time: 0.010304689407348633 seconds\n",
            "Extracting features for filtered_signal_7...\n",
            "Time domain feature extraction time: 0.006194114685058594 seconds\n",
            "Frequency domain feature extraction time: 0.002353668212890625 seconds\n",
            "Extracting features for filtered_signal_8...\n",
            "Time domain feature extraction time: 0.014285564422607422 seconds\n",
            "Frequency domain feature extraction time: 0.006506204605102539 seconds\n",
            "Extracting features for filtered_signal_9...\n",
            "Time domain feature extraction time: 0.005400180816650391 seconds\n",
            "Frequency domain feature extraction time: 0.002415180206298828 seconds\n",
            "Extracting features for filtered_signal_10...\n",
            "Time domain feature extraction time: 0.009078264236450195 seconds\n",
            "Frequency domain feature extraction time: 0.011232137680053711 seconds\n",
            "Extracting features for filtered_signal_11...\n",
            "Time domain feature extraction time: 0.013736486434936523 seconds\n",
            "Frequency domain feature extraction time: 0.007324934005737305 seconds\n",
            "Extracting features for filtered_signal_12...\n",
            "Time domain feature extraction time: 0.010134458541870117 seconds\n",
            "Frequency domain feature extraction time: 0.0068895816802978516 seconds\n",
            "Extracting features for filtered_signal_13...\n",
            "Time domain feature extraction time: 0.006764888763427734 seconds\n",
            "Frequency domain feature extraction time: 0.002391815185546875 seconds\n",
            "Extracting features for filtered_signal_14...\n",
            "Time domain feature extraction time: 0.00582432746887207 seconds\n",
            "Frequency domain feature extraction time: 0.00695037841796875 seconds\n",
            "Extracting features for filtered_signal_15...\n",
            "Time domain feature extraction time: 0.01276707649230957 seconds\n",
            "Frequency domain feature extraction time: 0.002931356430053711 seconds\n",
            "Extracting features for filtered_signal_16...\n",
            "Time domain feature extraction time: 0.009908199310302734 seconds\n",
            "Frequency domain feature extraction time: 0.00251007080078125 seconds\n",
            "Extracting features for filtered_signal_17...\n",
            "Time domain feature extraction time: 0.012658834457397461 seconds\n",
            "Frequency domain feature extraction time: 0.0025758743286132812 seconds\n",
            "Extracting features for filtered_signal_18...\n",
            "Time domain feature extraction time: 0.008867502212524414 seconds\n",
            "Frequency domain feature extraction time: 0.009021282196044922 seconds\n",
            "Feature extraction time: 0.36281752586364746 seconds\n",
            "Clustering time: 0.007265329360961914 seconds\n",
            "Assigning to clusters time: 0.00669550895690918 seconds\n",
            "KNN training time: 0.0033829212188720703 seconds\n",
            "Test Set Performance:\n",
            "Accuracy: 1.0\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           1.00         4\n",
            "   macro avg       1.00      1.00      1.00         4\n",
            "weighted avg       1.00      1.00      1.00         4\n",
            "\n",
            "Confusion Matrix:\n",
            " Predicted  0  All\n",
            "Actual           \n",
            "0          4    4\n",
            "All        4    4\n",
            "No seizure detected.\n",
            "Total execution time(Computation complexity): 0.7368907928466797 seconds\n"
          ]
        }
      ]
    }
  ]
}